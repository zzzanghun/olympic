{"Num/train": 90, "Num/episodes": 984, "Num/timesteps": 364000, "Train/episode_reward_mean": -120.0653333333334, "Train/ratio": {"_type": "histogram", "values": [12, 45, 91, 60, 31, 7, 1, 4, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "bins": [0.9394574761390686, 0.9615352153778076, 0.9836129546165466, 1.0056906938552856, 1.0277683734893799, 1.0498461723327637, 1.071923851966858, 1.0940016508102417, 1.116079330444336, 1.1381571292877197, 1.160234808921814, 1.1823124885559082, 1.204390287399292, 1.2264679670333862, 1.24854576587677, 1.2706234455108643, 1.292701244354248, 1.3147789239883423, 1.336856722831726, 1.3589344024658203, 1.381012201309204, 1.4030898809432983, 1.4251675605773926, 1.4472453594207764, 1.4693230390548706, 1.4914008378982544, 1.5134785175323486, 1.5355563163757324, 1.5576339960098267, 1.5797117948532104, 1.6017894744873047, 1.6238672733306885, 1.6459449529647827]}, "Loss/actor_loss": -0.28790868393649555, "Loss/critic_loss": 77.99286448441099, "Loss/entropy_loss": -0.012030522388182446, "_timestamp": 1698086808.047789, "_runtime": 7122.603334188461, "_step": 2, "_wandb": {"runtime": 8196}}